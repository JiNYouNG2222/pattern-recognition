{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPixLdWx1JENj6pLFEgP0Pr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiNYouNG2222/pattern-recognition/blob/main/final_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXTrRf3RPaV0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output\n",
        "from itertools import product\n",
        "\n",
        "'''\n",
        "learning_rate = [0.001, 0.0001]\n",
        "batch_size = [16, 32, 64, 128]\n",
        "num_classes = 26\n",
        "epochs = 30\n",
        "drop_out = [0.1, 0.3, 0.5]\n",
        "'''\n",
        "\n",
        "\n",
        "learning_rates = [0.001, 0.0001]\n",
        "batch_sizes = [16, 32, 64, 128]\n",
        "drop_outs = [0.1, 0.3, 0.5]\n",
        "features = [1025, 2048, 1000, 512, 256]\n",
        "num_classes = 26\n",
        "epochs = 30\n",
        "\n",
        "for learning_rate, batch_size, drop_out, feature in product(learning_rates, batch_sizes, drop_outs, features):\n",
        "    # 디바이스 설정 (CUDA 사용 가능 시 GPU 사용)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 데이터셋 및 데이터 로더 설정\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()  # 이미지를 텐서로 변환\n",
        "    ])\n",
        "\n",
        "    train_set = torchvision.datasets.EMNIST(\n",
        "        root='./data/EMNIST',\n",
        "        split='letters',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "    test_set = torchvision.datasets.EMNIST(\n",
        "        root='./data/EMNIST',\n",
        "        split='letters',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    #####\n",
        "    # 신경망 모델 정의\n",
        "    class NeuralNet(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # 합성곱 계층 정의\n",
        "            self.layer1 = nn.Sequential(\n",
        "                nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "                nn.BatchNorm2d(16),  # 배치 정규화\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "            self.layer2 = nn.Sequential(\n",
        "                nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "            self.layer3 = nn.Sequential(\n",
        "                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "            self.layer4 = nn.Sequential(\n",
        "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "            self.dropout = nn.Dropout(p=drop_out)\n",
        "            self.fc1 = nn.Linear(128 * 3 * 3, feature)\n",
        "            self.fc2 = nn.Linear(feature, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = self.layer3(x)\n",
        "            x = self.layer4(x)\n",
        "            x = x.view(x.size(0), -1)  # Flatten\n",
        "            x = self.dropout(x)\n",
        "            x = self.fc1(x)\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    #####\n",
        "\n",
        "    # 모델 초기화, 손실 함수 및 최적화 기법 설정\n",
        "    net = NeuralNet().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    # 훈련 루프\n",
        "    pd_results = []\n",
        "    test_accuracy = -987654321\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels - 1)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 손실 및 정확도 누적\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels - 1).sum().item()\n",
        "\n",
        "        # 에포크당 손실 및 정확도 계산\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_accuracy = 100. * correct / total\n",
        "\n",
        "        results = OrderedDict()\n",
        "        results['epoch'] = epoch + 1\n",
        "        results['loss'] = epoch_loss\n",
        "        results['accuracy'] = epoch_accuracy\n",
        "        pd_results.append(results)\n",
        "        df = pd.DataFrame.from_dict(pd_results, orient='columns')\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        print(f'Info : {learning_rate, batch_size, drop_out, feature}')\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "        print(df.tail())\n",
        "\n",
        "        # 에포크마다 테스트 세트에서 평가\n",
        "        net.eval()\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "        import time\n",
        "        st = time.time()\n",
        "        with torch.no_grad():\n",
        "            for images_test, labels_test in test_loader:\n",
        "                images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
        "                outputs_test = net(images_test)\n",
        "                _, predicted_test = torch.max(outputs_test.data, 1)\n",
        "                total_test += labels_test.size(0)\n",
        "                correct_test += (predicted_test == labels_test - 1).sum().item()\n",
        "        _test_accuracy = 100. * correct_test / total_test\n",
        "        print(f\"Test Accuracy: {_test_accuracy:.2f}%\")\n",
        "        print(f'time cost : {time.time()-st} sec')\n",
        "\n",
        "        print(f\"Max acc test : {test_accuracy if test_accuracy > _test_accuracy else _test_accuracy:.2f}%\")\n",
        "        if _test_accuracy > test_accuracy:\n",
        "            test_accuracy = _test_accuracy\n",
        "            torch.save({\n",
        "                'model_state_dict': net.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, \"emnist_4layer_ver7.pth\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "num_classes = 26\n",
        "epochs = 30\n",
        "Drp = 0.5\n",
        "\n",
        "\n",
        "train_set = torchvision.datasets.EMNIST(\n",
        "    root = './data/EMNIST',\n",
        "    split = 'letters',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
        "    ])\n",
        ")\n",
        "test_set = torchvision.datasets.EMNIST(\n",
        "    root = './data/EMNIST',\n",
        "    split = 'letters',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
        "    ])\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "print(train_set, test_set)\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "\n",
        "#####\n",
        "# 신경망 모델 정\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),  # Batch Normalization\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 28x28 -> 14x14\n",
        "        )\n",
        "\n",
        "        # Layer 2\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),  # Batch Normalization\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 14x14 -> 7x7\n",
        "        )\n",
        "\n",
        "        # Layer 3\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),  # Batch Normalization\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 7x7 -> 3x3\n",
        "        )\n",
        "\n",
        "        # Layer 4\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),  # Batch Normalization\n",
        "            nn.ReLU()\n",
        "            # No pooling, keeps 3x3 spatial dimension\n",
        "        )\n",
        "\n",
        "        # Dropout and Fully Connected Layers\n",
        "        self.dropout = nn.Dropout(p=Drp)\n",
        "        self.fc1 = nn.Linear(in_features=128 * 3 * 3, out_features=1000)\n",
        "        self.fc2 = nn.Linear(in_features=1000, out_features=26)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = x.reshape(x.size(0), -1)  # Flatten\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "#####\n",
        "\n",
        "\n",
        "# 모델 초기화, 손실 함수 및 최적화 기법 설정\n",
        "net = NeuralNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "# 훈련 루프\n",
        "pd_results = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        out = net(images)\n",
        "        loss = criterion(out, labels-1)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total = labels.size(0)\n",
        "        preds = torch.max(out.data, 1)[1]\n",
        "        correct = (preds==labels-1).sum().item()\n",
        "\n",
        "        if (i+1)%200==0:\n",
        "            results = OrderedDict()\n",
        "            results['epoch'] = epoch+1\n",
        "            results['idx'] = i+1\n",
        "            results['loss'] = loss.item()\n",
        "            results['accuracy'] = 100.*correct/total\n",
        "            pd_results.append(results)\n",
        "            df = pd.DataFrame.from_dict(pd_results, orient='columns')\n",
        "\n",
        "            clear_output(wait=True)\n",
        "            # display(df)\n",
        "            print(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "QedhFjclQu4D",
        "outputId": "f8443acc-172d-44f9-d179-20f5c8b23ac5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     epoch  idx      loss  accuracy\n",
            "0        1  200  0.699922  77.34375\n",
            "1        1  400  0.514354  84.37500\n",
            "2        1  600  0.248082  90.62500\n",
            "3        1  800  0.458122  89.06250\n",
            "4        2  200  0.398733  87.50000\n",
            "..     ...  ...       ...       ...\n",
            "115     29  800  0.210001  96.87500\n",
            "116     30  200  0.084324  96.87500\n",
            "117     30  400  0.123423  94.53125\n",
            "118     30  600  0.049325  99.21875\n",
            "119     30  800  0.202616  93.75000\n",
            "\n",
            "[120 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d360a7bf95e4>\u001b[0m in \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m torch.save({\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m }, \"emnist_4layer_ver6.pth\")\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = NeuralNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': net.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "}, \"emnist_4layer_ver6.pth\")\n"
      ],
      "metadata": {
        "id": "a5wZ6_G6TldK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 state_dict 출력\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# 옵티마이저의 state_dict 출력\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxPMmbISU2fm",
        "outputId": "d9236395-40c5-4fa8-f9bf-87948f931f6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "layer1.0.weight \t torch.Size([16, 1, 3, 3])\n",
            "layer1.0.bias \t torch.Size([16])\n",
            "layer1.1.weight \t torch.Size([16])\n",
            "layer1.1.bias \t torch.Size([16])\n",
            "layer1.1.running_mean \t torch.Size([16])\n",
            "layer1.1.running_var \t torch.Size([16])\n",
            "layer1.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.weight \t torch.Size([32, 16, 3, 3])\n",
            "layer2.0.bias \t torch.Size([32])\n",
            "layer2.1.weight \t torch.Size([32])\n",
            "layer2.1.bias \t torch.Size([32])\n",
            "layer2.1.running_mean \t torch.Size([32])\n",
            "layer2.1.running_var \t torch.Size([32])\n",
            "layer2.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.weight \t torch.Size([64, 32, 3, 3])\n",
            "layer3.0.bias \t torch.Size([64])\n",
            "layer3.1.weight \t torch.Size([64])\n",
            "layer3.1.bias \t torch.Size([64])\n",
            "layer3.1.running_mean \t torch.Size([64])\n",
            "layer3.1.running_var \t torch.Size([64])\n",
            "layer3.1.num_batches_tracked \t torch.Size([])\n",
            "layer4.0.weight \t torch.Size([128, 64, 3, 3])\n",
            "layer4.0.bias \t torch.Size([128])\n",
            "layer4.1.weight \t torch.Size([128])\n",
            "layer4.1.bias \t torch.Size([128])\n",
            "layer4.1.running_mean \t torch.Size([128])\n",
            "layer4.1.running_var \t torch.Size([128])\n",
            "layer4.1.num_batches_tracked \t torch.Size([])\n",
            "fc1.weight \t torch.Size([1000, 1152])\n",
            "fc1.bias \t torch.Size([1000])\n",
            "fc2.weight \t torch.Size([26, 1000])\n",
            "fc2.bias \t torch.Size([26])\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 1e-05, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(emnist_4layer_ver6.pth)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "yAd0k9p0RV1r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}